# 线性代数

## 向量

向量是一个可以进行加法和数乘的元素

## 行列式

行列式是一个将n阶方阵映射为一个数的函数

行列式可以提取倍数，但是提取出的倍数要以行列式的阶数作为幂次

![image-20250616101737510](./assets/image-20250616101737510.png)





**行列式的值=主对角线元素乘积-负对角线元素乘积**

二列行列式很好求解

![image-20250615154733346](./assets/image-20250615154733346.png)

二阶行列式的几何意义：由向量形成的平行四边形的面积

![img](./assets/25221436-46d5a61553b1456da9ace01a92365572.png)

三阶行列式的几何意义：由行向量/列向量形成的平行六面体的有向体积

![img](./assets/25221536-0c07cfb04cc947d8acae4b69cdb43331.png)



n阶行列式的几何意义：由行向量/列向量形成形成的一个n维平行多面体的体积







对于二阶以上的行列式，需要通过初等变化转换为**为上三角形或下三角形**，再求解对角线元素乘积之差



行列式的初等变换有一些额外的规则：

+ 可以对列进行操作
+ 可以将公因数提取到行列式外部
+ 交换某行(列)需要补一个-1
+ 行列式的转置=本身
+ 如果存在成比例的行/列，那么行列式的值为0
+ 如果某行/列的值等于其他两行/列的元素之和，那么可以从这一行/列拆开

<img src="./assets/image-20250625083150857.png" alt="image-20250625083150857" style="zoom:50%;" />



## 矩阵

矩阵乘法不满足交换律



![image-20250616101501342](./assets/image-20250616101501342.png)



矩阵中不存在**矩阵+数字**，只有矩阵+数字E(E是单位矩阵)



已知AX=AB，不能推出X=B，要首先判断**A是否可逆**，如果可逆则经过变换得到有X=B



注意所有用到A的逆的证明，都需要先判断A是否可逆

![image-20250617083944239](./assets/image-20250617083944239.png)

转置矩阵性质如下



 ![image-20250617090056243](./assets/image-20250617090056243.png)





矩阵的迹=矩阵主对角线元素的和







## 矩阵的秩

矩阵的秩：矩阵中线性无关的向量的个数，线性无关指的是向量不能被其他向量线性表示出来。





秩的性质



+ **转置后秩不变**
+ **r(A)<=min(m,n),A是m*n型矩阵**
+ **r(kA)=r(A),k不等于0**
+ **![image-20250617090501383](./assets/image-20250617090501383.png)**，或者会表示A的秩等于其阶数
+ 初等变化不会改变矩阵的秩





列满秩：秩等于矩阵的列，组成矩阵的向量之间线性无关

行满秩：**秩等于矩阵的行数**



矩阵的秩可以指出矩阵有几个解

初等变换化成行最简形（或行阶梯形），然后数一下非零行数，行最简形需要满足以下条件：

1. 首先将矩阵化为阶梯型
2. 将每行的第一个非0数化为1
3. 保证每行第一个非0数所在列其余数都是0

![在这里插入图片描述](./assets/78632de547a5483370557b7218efbfe5.png)



为什么化为行最简形后，数非零行个数就可以算出秩？对矩阵做初等变换不会改变行向量的线性相关性。



什么时候AB=BA：对角矩阵或者有倍数关系

## 逆矩阵

对于方阵A，如果存在方阵B使得：AB=BA=E，那么A可逆，B为A的逆矩阵。

![image-20250625083544697](./assets/image-20250625083544697.png)



逆矩阵的性质

+ 若A可逆，$A^{-1}$也可逆，且 $(A^{-1})^{-1} = A$；
+ 若A可逆，$A^T$（转置矩阵）也可逆，且$(A^T)^{-1} = (A^{-1})^T$；
+ 若$k \ne 0$，则数乘矩阵 $kA$ 也可逆，且$(kA)^{-1} = \frac{1}{k}A^{-1}$；
+ 若$A, B$ 均可逆，则乘积$AB 也可逆，且$(AB)^{-1} = B^{-1}A^{-1}$。



伴随矩阵是由原始矩阵的代数余子式构成的矩阵再转置得到的，常用于矩阵求逆，代数余子式 $C_{ij}$的计算过程如下

- **去掉第 $i$ 行和第 $j$ 列**，得到一个 $(n-1) \times (n-1)$ 子矩阵 $M_{ij}$
- **计算该子矩阵的行列式：** $\det(M_{ij})$
- **乘上符号因子 $(-1)^{i+j}$**



伴随矩阵具有以下性质

如果 $\det(A) \ne 0(行列式)$则：
$$
A^{-1} = \frac{1}{\det(A)} \cdot \text{adj}(A)
$$






## 矩阵求逆

如果行列式的值=0，那么矩阵可逆，反之不可逆；如果矩阵是满秩的那么可逆。





待定系数法

![这里写图片描述](./assets/5fd886fc6be7070eb68cc974d3544e83.png)

初等变化法

将矩阵和一个同大小的**单位矩阵**增广一下，然后进行初等变换

![这里写图片描述](./assets/6e87419eb40fe8b0e628961f153c3f98.png)



## 线性方程组的解

无解的充要条件是**R(A)<R(A,b)**，反之有解的充要条件是R(A)=R(A,b)

![image-20250611100956719](./assets/image-20250611100956719.png)

- 如果R(A)=R(A,b)=n，有唯一解，这里的n是列数
- 小于n，无穷多解
- 小于n且齐次，零解+无穷多个非零解





## 向量是否能组线性表示

向量b能被向量组A线性表示，等价于AX=b有解，等价于R(A,b)=R(A)

如果两个矩阵等价(能相互线性表示)：则R(A)=R(B)=R(A,B)

向量组线性相关：存在一个向量能被其余的向量线性表示

整体无关则部分无关，部分相关则整体相关





## 极大无关组

极大无关组：在线性无关的条件下，能找出的最大的向量子集

如果能向量组A中选出r个向量组成的向量组$A_0$，满足$A_0$线性无关，同时A中任意r+1个向量都线性相关，那么称$A_0$是A的一个极大无关组——A中任意向量都能被$A_0$表示，$A_0$中向量的个数就是A的秩。

求法：求秩后，每行第一个非0数所在的列对应的向量

![image-20250614091224700](./assets/image-20250614091224700.png)









## 用极大无关组表示向量

![image-20250614094408072](./assets/image-20250614094408072.png)

首先求解极大无关组，得到$\alpha_1和\alpha_3$是极大无关组

![image-20250614094425656](./assets/image-20250614094425656.png)



将其余向量用对应的数值(竖向)表示，以$\alpha_2为例$，其可以表示为：

$-1\times极大无关组的第一个+0\times极大无关组的第一个+0\times极大无关组的第一个+0\times极大无关组的第一个$

如果极大无关组数量不够，则认为是0

![image-20250614094741240](./assets/image-20250614094741240.png)







## 线性空间

令V是n维向量的集合，如果V非空，且V对于向量的线性运算封闭，那么V就称为线性空间，线性空间的极大无关组称为线性空间的基。

- **向量加法**：$V + V \to V$
- **数乘（数量乘法）**：$\mathbb{F} \times V \to V$

满足以下八个性质，那么就称V是一个线性空间

<img src="./assets/image-20250624084341815.png" alt="image-20250624084341815" style="zoom:50%;" />







线性子空间：如果U是一个属于V的非空集合，并且满足

<img src="./assets/image-20250624084629466.png" alt="image-20250624084629466" style="zoom:67%;" />

那么U是V的一个线性子空间





## 正交矩阵

如果两个向量的内积为0，那么二者正交，0向量与任何向量都正交，一组两两正交的非0向量称为正交向量组，正交向量组一定线性无关。





如果方阵A满足$A^TA=E$，那么称A是一个正交矩阵，同时$A^{-1}=A^T$





正交变换：$\boldsymbol{x} \mapsto P\boldsymbol{x}$，其中P是一个正交矩阵。



首先求解出矩阵的特征值和特征向量，这里的特征向量需要合并以及将K提入

<img src="./assets/image-20250616093538163.png" alt="image-20250616093538163" style="zoom:50%;" />

然后依次填入，得到

![image-20250616094324292](./assets/image-20250616094324292.png)

这里需要给定未知数的值，但每一列的取值可以不同即第一列的k1可以不等于第二列的k1，并且需要满足：任意两列之间的乘积等于0。一种简单的方法是：第一列的K1为0，其余设置为0；第二列的K2为1，其余设置为0；第三列的K3为1，其余设置为0，这样可以快速求解出满足条件的未知数。

最后<img src="./assets/image-20250616094556483.png" alt="image-20250616094556483" style="zoom:67%;" />





正交变换可以化二次型为标准型

正交变化可以研究图形的几何性质，因为经过正交变换后，向量的模不会变化；两个向量经过正交变换后，它们之间的夹角不会变换。因此可以通过正交变化旋转，镜像图形。







## 特征值

若有数λ及非零向量ξ，使Αξ=λξ，那么λ是矩阵对应的特征值，ξ是其特征向量。





对于**行数等于列数**的矩阵求解特征值

<img src="./assets/image-20250615160629832.png" alt="image-20250615160629832" style="zoom:50%;" />

令该式子等于0，得到

<img src="./assets/image-20250615160656415.png" alt="image-20250615160656415" style="zoom:67%;" />

注意矩阵或者说方阵的特征值的个数等于其行数或者列数，最后解出了两个值说明第三个特征值和前面的某一个特征值重复了，因此有

<img src="./assets/image-20250615160907788.png" alt="image-20250615160907788" style="zoom:50%;" />





## 求解矩阵的特征向量

![image-20250616092345234](./assets/image-20250616092345234.png)



在得到特征值后，依次对每种特征值操作：将主对角线减去特征值，然后扩展一维0向量，求通解

![image-20250616092352279](./assets/image-20250616092352279.png)

![image-20250616092447439](./assets/image-20250616092447439.png)

那么特征向量就是，但是注意特征向量与通解不同，这里的k1和k2不能全为0

![image-20250616092505475](./assets/image-20250616092505475.png)

## 特征值求可逆矩阵

定义：矩阵A为n阶方阵，若存在n阶矩阵B，使得矩阵A、B的乘积为单位阵，则称A为可逆阵，B为A的逆矩阵。



首先求解特征值和特征向量

**主对角线上为特征值的矩阵就是对角矩阵，将k1,k2,k3对应的向量依次填入矩阵(竖向)就是可逆矩阵**

![image-20250616095131300](./assets/image-20250616095131300.png)

## 求二次型f的矩阵

二次型：多个变量的二次多项式，没有一次项和常数项



线性代数里的二次型是通过矩阵来研究二次函数



<img src="./assets/image-20250616095429360.png" alt="image-20250616095429360" style="zoom:67%;" />

将$x_ix_j$的系数划分一半给(i,j)一半给(j,i)





对于方阵A和B，如果存在可逆矩阵，使得$C^TAC=B$，那么A与B合同，把A化为B的变换成为合同变换。



二次型研究的主要问题是，寻找可逆线性变换x=Cy，使

**![image-20250626090750923](./assets/image-20250626090750923.png)**

这种只含平方项的二次型称为标准型，如果标准型的系数只在-1,1,0中取值，那么这个标准形称为二次型的规范型。





想要变为只有二次项，那么$C^TAC$需要是一个对角矩阵(只有对角线上有元素)，A矩阵本身是一个对称矩阵，而对称矩阵总有正交矩阵P使得$P^{-1}AP$为对角矩阵，正交矩阵$P^{-1}=P^T$，因此经过正交变换可以化二次型为标准型。

惯性定理：二次型的标准型中系数中正数的个数是确定的。正/负系数的个数称为二次型的正/负指数。



# 概率论

## 概率公式

<img src="./assets/image-20250615161517152.png" alt="image-20250615161517152" style="zoom:67%;" />



注意对立和互斥不等价；A包含于B，AB发生的概率等于小的事件发生的概率

<img src="./assets/image-20250615162246076.png" alt="image-20250615162246076" style="zoom:50%;" />





## 古典概型

古典概型具有以下两种特征：

- 每次实验只有有限种结果
- 每次实验中，各基本事件出现的可能性完全相同



**P{结果数}=符合结果的情况数*P{符合结果的某个情况}**

<img src="./assets/image-20250615164433332.png" alt="image-20250615164433332" style="zoom:67%;" />



几何概型：随机实验的样本空间是一个区域(直线上的区间)，而且样本空间中每个实验结果出现的可能都相同。





## 独立性、相关性、互斥性

独立——互不影响

相关性——变量之间存在某种趋势，正相关/负相关，独立=>不相关，但反过来不行。

互斥——不能同时发生



## 贝叶斯公式是什么，有什么应用

由果推因

![image-20250613091224301](./assets/image-20250613091224301.png)

- $P(A|B)$：已知 B 发生的条件下，A 发生的概率（**后验概率**）
- $P(A)$：A 本身发生的概率（**先验概率**）
- $P(B|A)$：A 发生时，B 发生的概率（**似然**）
- $P(B)$：B 发生的总概率（**标准化因子**）

也称为后验概率



## 全概率公式

设 $A_1, A_2, \dots, A_n$ 是一个**完备事件组**（即两两互斥，且覆盖全集），那么对任意事件$B$有：

![image-20250613091409623](./assets/image-20250613091409623.png)





## 离散型随机变量

若随机变量的取值是有限个，则称X是离散型随机变量



重要分布有：



0-1分布



二项分布，n重伯努利实验中A发生的次数

<img src="./assets/image-20250616110905921.png" alt="image-20250616110905921" style="zoom:67%;" />



泊松分布

![image-20250616110935178](./assets/image-20250616110935178.png)

性质

![image-20250616105808277](./assets/image-20250616105808277.png)

几何分布(直到第一次成功所需的操作次数)

![image-20250616111050152](./assets/image-20250616111050152.png)



| 分布类型     | 分布记号                       | 期望（Expectation）           | 方差（Variance）                      | 备注说明                                         |
| ------------ | ------------------------------ | ----------------------------- | ------------------------------------- | ------------------------------------------------ |
| **二项分布** | $X \sim \mathrm{Bin}(n, p)$    | $\mathbb{E}[X] = np$          | $\mathrm{Var}(X) = np(1-p)$           | 成功次数总共 $n$ 次独立试验                      |
| **泊松分布** | $X \sim \mathrm{Poi}(\lambda)$ | $\mathbb{E}[X] = \lambda$     | $\mathrm{Var}(X) = \lambda$           | 事件单位时间平均到达率为 $\lambda$               |
| **几何分布** | $X \sim \mathrm{Geom}(p)$      | $\mathbb{E}[X] = \frac{1}{p}$ | $\mathrm{Var}(X) = \frac{1 - p}{p^2}$ | 第一次成功所需试验次数（支持集为 $1,2,3,\dots$） |



分布函数：设X是一个随机变量，x是一个实数，则函数F(x)=P{X<=x}，满足以下性质

+ 单调不减
+ 有界性：0<=F(x)<=1
+ 连续性：F(x+0)=F(x)，是一个右连续函数





## 连续型随机变量

设F(x)是随机变量的分布函数，若存在非负的可积函数f(x)，使得对任意实数x都有$F(x)=\int_{-\infty}^{x} f(t) \, dt$(F(x)等于f(t)从0到负无穷的积分)，那么称X是一个连续型随机变量，f(x)是x的概率密度函数。



概率密度函数满足以下性质：

+ f(x)>=0
+ $\int_{-\infty}^{\infty} f(t) \, dt=1$
+ P{X=a}=0



![image-20250617091622312](./assets/image-20250617091622312.png)

<img src="./assets/image-20250617091751654.png" alt="image-20250617091751654" style="zoom:67%;" />

重要分布如下:

+ 均匀分布

  <img src="./assets/image-20250626101847554.png" alt="image-20250626101847554" style="zoom:67%;" />

<img src="./assets/image-20250617094623465.png" alt="image-20250617094623465" style="zoom:67%;" />



+ 指数分布

![image-20250617094733412](./assets/image-20250617094733412.png)

<img src="./assets/image-20250617094740326.png" alt="image-20250617094740326" style="zoom:67%;" />

  指数分布具有无记忆性

![image-20250617095007443](./assets/image-20250617095007443.png)



+ 正态分布，关于u对称，在u处达到最大值，通过$\frac{x-\mu}{\delta}$可以转换为标准正态分布。

![image-20250617095029785](./assets/image-20250617095029785.png)









| 分布名称                         | 密度函数 $f(x)$                                            | 定义域                 | 期望 $\mathbb{E}(X)$ | 方差 $\mathrm{Var}(X)$ |
| -------------------------------- | ---------------------------------------------------------- | ---------------------- | -------------------- | ---------------------- |
| 均匀分布 $U(a,b)$                | $\frac{1}{b-a}$                                            | $a \le x \le b$        | $\frac{a+b}{2}$      | $\frac{(b-a)^2}{12}$   |
| 指数分布 $\mathrm{Exp}(\lambda)$ | $\lambda e^{-\lambda x}$                                   | $x \ge 0$              | $\frac{1}{\lambda}$  | $\frac{1}{\lambda^2}$  |
| 标准正态分布 $N(0,1)$            | $\frac{1}{\sqrt{2\pi}} e^{-x^2/2}$                         | $-\infty < x < \infty$ | $0$                  | $1$                    |
| 正态分布 $N(\mu,\sigma^2)$       | $\frac{1}{\sqrt{2\pi\sigma^2}} e^{-(x-\mu)^2/(2\sigma^2)}$ | $-\infty < x < \infty$ | $\mu$                | $\sigma^2$             |





## 期望和方差

期望是度量一个随机变量取值的集中位置或平均水平的最基本的数字特征

方差用于分析某组数据内部的集中程度或者是离散程度，

- 方差越小，数据越集中，内部波动越小，比较稳定
- 方差越大，数据的离散程度越高，内部波动大，不稳定



离散型随机变量

![image-20250617095949664](./assets/image-20250617095949664.png)

连续型随机变量

![image-20250617100009661](./assets/image-20250617100009661.png)



期望运算的性质

![image-20250617100124670](./assets/image-20250617100124670.png)

方差运算的性质

![image-20250617100140021](./assets/image-20250617100140021.png)

![image-20250619082712287](./assets/image-20250619082712287.png)



二者之间的联系

![image-20250617100242865](./assets/image-20250617100242865.png)

协方差

![image-20250619083523239](./assets/image-20250619083523239.png)

当X=Y时，求解的就是X or Y的方差



![image-20250619083820358](./assets/image-20250619083820358.png)



相减也是可以拆开的



相关系数，如果等于0，表示两个变量不相关，不相关推不出独立，独立可以推出不相关

![image-20250619083603449](./assets/image-20250619083603449.png)



样本的方差，这里的n-1实际是为了修正

![image-20250621091140918](./assets/image-20250621091140918.png)

方差的计算公式中

![image-20250621092105490](./assets/image-20250621092105490.png)

会用样本均值代替u，但是这样估计出的方差会比实际的值要小一点

<img src="./assets/image-20250621092138751.png" alt="image-20250621092138751" style="zoom:67%;" />

因此需要稍微放大一点



## 切比雪夫不等式

知道随机变量的期望和方差就可以对随机变量的概率分布进行估计



![image-20250626103851404](./assets/image-20250626103851404.png)



## 矩

原点矩：$E(X^k)$称为X的k阶原点矩，随机变量X的一阶原点矩就是它的数学期望E(X)

中心矩：$E((X-E(X))^k)$称为X的k阶中心矩，随机变量X的二阶中心矩就是它的方差$D(X)=E[((X一E(X))^2]$

## 大数定律

如果存在一个常数a，使得对任意$\varepsilon>0 有\lim_{n \to \infty} P\left( |Y_n - a| < \varepsilon \right) = 1$，那么称随机变量序列依概率收敛于a。



辛钦大数定律(强大数定律)：对于独立同分布的随机变量序列

![image-20250626105458836](./assets/image-20250626105458836.png)

伯努利大数定律(弱大数定律)：如果$u_n$是n次独立重复实验的中A发生的次数，p是事件A在每次实验中发生的概率

![image-20250626105630296](./assets/image-20250626105630296.png)

切比雪夫大数定律(弱大数定律)：要求随机变量是独立的

![image-20250626105922230](./assets/image-20250626105922230.png)



弱大数定律：当样本数量足够大的时候，均值必然趋近定值

<img src="./assets/v2-067587d05f845573c32084c0f70409ec_1440w.jpg" alt="img" style="zoom:50%;" />

强大数定律：当样本数量足够大的时候，均值逼近于定值的概率趋近于1

<img src="./assets/v2-869678154115eef7e28b029deac2be39_1440w.jpg" alt="img" style="zoom:50%;" />







## 中心极限定理

对于一组相互独立的随机变量，在样本数量足够大的情况下，样本均值会近似服从正态分布



独立同分布的中心极限定理：如果一组变量服从独立同分布，样本数量趋于无穷时它们的均值服从近似正态分布。

![image-20250627084352019](./assets/image-20250627084352019.png)





李雅普诺夫定理：随机变量相互独立，当样本数量足够大的时候可以样本均值近似正态分布，要求期望，方差，高阶中心矩存在

拉普拉斯定理:当样本数量足够大的时候，二项分布可以用正态分布来近似。





## 数理统计三大分布

$χ^2$分布

<img src="./assets/image-20250619122802887.png" alt="image-20250619122802887" style="zoom:67%;" />



 t分布

<img src="./assets/image-20250619122816234.png" alt="image-20250619122816234" style="zoom:67%;" />



F分布

![image-20250619122931673](./assets/image-20250619122931673.png)





## 参数估计

### 矩估计

当样本数量足够大的时候，总体矩=样本矩



矩的定义：随机变量的N阶矩就是其N次幂的期望



求解过程：先求出总体矩，然后令样本均值(已知)等于总体矩，反解出参数





### 最大似然估计

利用已知样本信息反推最有可能导致这些样本结果出现的模型参数值——在所有可能的参数中找一个能使结果最有可能发生的(既然已经发生了，为什么不然它发生的概率最大)



有一枚**来路不明的硬币**，你不知道它正面（记为1）朝上的概率是多少。现扔了10次，发现：7次正面，3次反面，那么直觉上这么硬币向上的概率为70%，用最大似然估计求解就是找到一个参数p使得$p^7\times (1-p)^3$最大，那么求导后带入p=0.7可以得到最大值。



求解能使最大似然函数结果最大的参数值

- 离散型：$L(\theta) = \prod_{i=1}^{n} p(x_i; \theta)$
- 连续型：$L(\theta) = \prod_{i=1}^{n} f(x_i; \theta)$

显然的，要求到找到驻点，由于连乘不好求导，因此一般会求对数似然函数，即给整个公式套一个**log**。



### 无偏性和有效性

无偏性：对于估计的参数$\hat{\theta}$，有E($\hat{\theta}$)=$\theta$

有效性：对于两个无偏性的参数a和b，方差更小的那个更有效











## 置信度和置信区间

置信度：有多大的把握认为置信区间包含测量值

置信区间：参数大概在哪个范围内

单侧置信区间：关心参数的上限和下限



## 假设检验

对总体分布的类型，或分布中的某些参数做出某种假定，然后抽取子样本并选择一个误差值对所做假设成立与否做出定性判断。

在假设检验判断样本正确与否时，会犯两类错误

- 第一类错误：弃真
- 第二类错误：留伪

一般来讲只能控制其中一类错误的可能



P值定义为假设原假设正确的情况下，发生极端情况的概率。



以抛硬币为例，原假设认为正反两面出现的次数为1/2，那么备择假设认为硬币有问题，极端的情况就是出现18，19，20次正/反面，计算他们出现的概率，假设为0.02，那么令a=0.05也就是认为概率小于0.05才认为出现可能很小，而0.02<0.05说明出现18，19，20次正/反面很小，在出现概率如此小的情况下都会出现，那么拒绝原假设，认为硬币是有问题的。







## 熵

信息论中用于衡量信息的不确定性，越混乱，不可预测的数据熵越大，反之越有规律可以预测的数据熵就小。



# 高数









## 极限

无穷/无穷：(1)只保留分子和分母的最高项，(2)洛必达，上下同时求导

0/0：(1)用等价无穷小替换，(2)洛必达，上下同时求导

<img src="./assets/283b568b8c2c850aa47f984f3bfd3c74.png" alt="img" style="zoom:50%;" />

$1^{\infty}$：![image-20250621121511759](./assets/image-20250621121511759.png)

$0\times \infty$：转换为无穷/无穷或0/0





证明极限是否存在——判断左极限=右极限=一个不为极限的数。



数列极限的定义：

![image-20250627102852825](./assets/image-20250627102852825.png)

函数极限的定义：

![image-20250627103347958](./assets/image-20250627103347958.png)



## 夹逼定理

![image-20250621124248317](./assets/image-20250621124248317.png)

## 连续和间断点

连续：在某个区间连贯且无端点，证明函数在某点连续——左极限=右极限=在该点的函数值





间断点可能是函数的分段点，或使分母为0的点，在这一点处不能连续。如果存在一点使得sin,cos的后的数为无穷且系数不为0，那么这一点可以直接判读为第二类间断点。



间断点分为三类：

- 可去间断点：左极限=右极限！=无穷
- 跳跃间断点：左极限!=右极限，且均不为无穷
- 第二类间断点：左极限右极限至少有一个是无穷



## 导数

![image-20250621120222259](./assets/image-20250621120222259.png)

![image-20250621120508796](./assets/image-20250621120508796.png)



链式法则，规定了复合函数求导的运算

![image-20250623140343556](./assets/image-20250623140343556.png)

![image-20250623140349490](./assets/image-20250623140349490.png)





函数在某点可导，令h是一个增量



![image-20250624085625440](./assets/image-20250627105347885.png)



函数在开区间内可导：函数在开区间内处处可导。

函数在闭区间内可导：函数在开区间内处处可导，且在左端点有右导数，右端点有左导数。





## 微分中值定理

给定平面上固定两个端点的可微曲线，那么曲线两个端点之间必然有一点，在该点的斜率等于两个端点连接起来的直线的斜率。



罗尔中值定理

1. 在闭区间[a,b]上连续
2. 在开区间(a,b)上可导
3. 有f(a)=f(b)

<img src="./assets/image-20250613120512175.png" alt="image-20250613120512175" style="zoom:67%;" />

若连接曲线端点的弦是水平的，则曲线上必然有一点，该点的切线是水平的。





拉格朗日中值定理，罗尔中值定理更**一般**的形式

1. 在闭区间[a,b]上连续
2. 在开区间(a,b)上可导



<img src="./assets/image-20250613120519519.png" alt="image-20250613120519519" style="zoom:67%;" />

曲线上总存在一点，该点的切线与连接曲线端点的弦平行







柯西中值定理，有两个函数f和g

1. 在闭区间[a,b]上连续
2. 在开区间(a,b)上可导
3. 对于(a,b)内任意一点x都有g`(x)!=0



<img src="./assets/image-20250613120833434.png" alt="image-20250613120833434" style="zoom:67%;" />

## 泰勒公式

用一个多项式去逼近给定的函数

![img](./assets/v2-d07ebfc631a0a8fa9b423e97490d4966_1440w.png)

- 想求a0，代入x=0
- 想求a1，求一次导，代入x=0
- 想求a2，再求一次导，代入x=0
- ...



要求函数在某点的泰勒公式

![image-20250627133056324](./assets/image-20250627133056324.png)

x0=0时，对应的泰勒公式就是麦克劳林公式



<img src="./assets/image-20250627133238439.png" alt="image-20250627133238439" style="zoom:67%;" />



## 单调性

F(x)在[a,b]连续，(a,b)上可导，

![image-20250627133551250](./assets/image-20250627133551250.png)

凹区间：F(x)在[a,b]连续，(a,b)上可导，且二阶导数大于0

凸区间：F(x)在[a,b]连续，(a,b)上可导，二阶导数小于0

拐点：凹凸区间的分界点



驻点：导数为0的位置，驻点不一定是极值点，极值点一定是驻点



## 曲率

曲率描述函数图像的弯曲程度

![image-20250628083426437](./assets/image-20250628083426437.png)



## 不定积分

不定积分是导数的逆运算，也叫反导数，具有数乘性和可加性

![image-20250628084107218](./assets/image-20250628084107218.png)















## 可微可导连续

连续不能推出可导，可导可以推出连续(绝对值)

可微和可导等价

可微可以推出连续











## 不定积分和定积分



定积分是求解一个函数的图像在闭区间上和X轴围成的面积



## 可微的定义

如果函数在某一点可微，那么在该点的导数存在且有限，那么函数在该点可导。



## 积分中值定理

函数f在闭区间[a,b]上连续，那么在积分区间中至少存在一点使得

![image-20250613122411458](./assets/image-20250613122411458.png)

推广：函数f在闭区间[a,b]上连续，函数g在闭区间[a,b]上连续不变好，那么有

![image-20250613123436018](./assets/image-20250613123436018.png)

念法：从 $a$ 到 $b$ 的 $f(x)g(x)$ 的定积分，等于某个点 $\xi$ 处的 $f(\xi)$，乘以从 $a$ 到 $b$ 的 $g(x)$ 的定积分。



## **什么是数列的极限，也就是说一个数列xn，收敛于a，你如何定义它？**

令a为一个定数，对任意给定的正数ε，总存在正整数N，使得n>N时有![image-20250613130030708](./assets/image-20250613130030708.png)

则称数列$a_n$收敛于a，定数a记为数列$a_n$的极限。

## **初等函数是什么？基本初等函数有哪几种？**

基本初等函数：幂函数，指数函数，对数函数，三角函数，反三角函数。

初等函数：由基本初等函数经过有限次的有理运算以及有限次的函数复合产生的。



## 什么是凸函数

函数曲线上任意两点连成的线段皆位于图形上方

## ex 的泰勒展开式





## 内积

两个向量相乘得到的一个标量，内积越大说明两个向量方向越近，内积为0则表示垂直。



## 欧式空间是什么

在线性空间的基础上再定义内积(向量对于相乘，可以理解为两个向量的数值乘上它们的cos夹角值)运算，就可以得到欧式空间









# 数据结构



## 数据结构的分类

- 存储结构分类：顺序存储，链式存储，散列表
- 逻辑分类：线性(一对一)，树形(一对多)，图(多对对)





## 排序的稳定性

对于两个相同大小的元素，如果排序后相对位置不变，那么说排序是稳定的。

- **选择排序、快速排序、希尔排序、堆排序不是稳定的排序算法。**
- **冒泡排序、插入排序、归并排序、基数排序是稳定的排序算法。**







## **如何判断一个单链表是否是循环链表（要给出一个比遍历更快的方法）**

快慢指针法：两个指针一个每次前进1步、一个每次前进2步，相遇则循环

## **说下快排过程**

分治法，选定一个分界值，分界值左边的都小于分界值、分界值右边的都大于分界值

## 快排时间复杂度

nlogn和n的平方，最坏是因为每次用于划分的数(原始数组有序)，恰好会把数组分为1和n-1，最好情况则是每次划分都很平衡切好分为两半。



## 如何判断有向图是否有环？

拓扑排序

## B树

B树是一个多叉平衡搜索树，每一个节点可以有多个值(关键字)，且包含对应记录的指针，节点内的值是有序的，也可以有多个分支。为磁盘/大数据存储系统设计的一种高效可扩展的数据结构，数据库的索引用的就是B树。

[参考视频](https://www.bilibili.com/video/BV1JU411d7iY?spm_id_from=333.788.player.switch&vd_source=63004f7ee2f738d6adc086e00ebcede2)

![image-20250617103621452](./assets/image-20250617103621452.png)

考虑6,13这个节点，它的子树1,4 8,11实际上对应的就是6的左右子树，8,11 14,16就是13的左右子树

对于M阶B树，每个节点最多有M个分支，包含M-1个元素；最少ceil(m/2)个分支，包含ceil(m/2)-1个元素，根节点可以是2个分支以及1个元素。

### 查找

以找28为例

![image-20250617104612229](./assets/image-20250617104612229.png)

这里回去找43的左子树，但是其左子树不存在，相当于走到了失败节点上，因此查找失败。



### 插入

以插入20为例

<img src="./assets/image-20250617104825294.png" alt="image-20250617104825294" style="zoom:50%;" />



最后会走到23所在节点，这里不是继续往下走而是直接将值加入到23所在的节点。



插入时可能会违反B树的规则，即一个节点中的元素数超过上限了。假设现在插入的17，那么它会被添加到3,14这个位置，此时节点内元素的个数会超出上限(上溢)，此时需要进行调整——将中间位置的元素上移到父节点，并将该节点划分为左右两部分。

<img src="./assets/image-20250617105232085.png" style="zoom:67%;" />

显然的上移后依然可能会违反规则，因此继续递归处理

<img src="./assets/image-20250617105428911.png" alt="image-20250617105428911" style="zoom:67%;" />



 B树的构建也是这样一点点调整出来的。



### 删除

[参考视频](https://www.bilibili.com/video/BV1JU411d7iY?spm_id_from=333.788.player.switch&vd_source=63004f7ee2f738d6adc086e00ebcede2)

删除B树上的非叶子节点，和二叉搜索树一样用中序的后继替换，然后删除替换后的节点。然后删除界点活可能会违反B树的规则——节点内元素的个数不够了(下溢)。

<img src="./assets/image-20250617110129825.png" alt="image-20250617110129825" style="zoom: 50%;" />

如果兄弟节点可以借一个，那么就从兄弟节点处借一个节点过来，左右随意。

这里不能借节点中的任意一个，做法是：将兄弟节点对应的父节点添加给下溢出的节点，然后将兄弟节点的中最大/最小(取决于是左兄弟还是右兄弟)的元素值上移，保证有序，父下来子上去。

注意如果兄弟节点也有子树那么需要移动该节点最左/最右的子树移动给溢出节点。

<img src="./assets/image-20250617110404064.png" alt="image-20250617110404064" style="zoom:50%;" />



如果兄弟节点不够借，那么需要合并

<img src="./assets/image-20250617110739510.png" alt="image-20250617110739510" style="zoom:50%;" />



和左兄弟合并——将其父节点移动到左兄弟，然后再合并，合并时也需要移动对应的子树

<img src="./assets/image-20250617110826434.png" alt="image-20250617110826434" style="zoom:67%;" />



这样父节点也会减少一个元素，可能发生下溢出，因此递归处理



## B+树

叶结点层包含全部的关键字以及指向相应记录的的指针，非叶子节点只是作为索引，节点之间通过链表连接，这样在顺序查找时可以避免中序遍历的方式在树上来回移动，兼顾了顺序查找和随机查找，以及范围查找(顺寻查找+随机查找)。

和B树不同，m个分支的节点有m个元素，同时非叶子节点的每个元素对应其子节点的最大值，叶子节点包含一个指向记录的指针

<img src="./assets/image-20250617120033506.png" alt="image-20250617120033506" style="zoom:67%;" />



B+树的查找需要一直走到叶子节点，不能中途停下



## 默克尔树

每个叶子节点是数据的哈希值，非叶子节点又是子节点的哈希值。

在密码学和区块链中十分重要，能高效的检验数据的完整性和一致性。

## 哈希表

哈希表的两种散列函数是：直接定值法(构造一个线性函数)，除留余数法(模一个数，模数寻选取小于等于表长的质数，可以减小冲突的可能)



解决哈希冲突的方法有：

+ 开放定址法：**去找另一个位置**
  + 线性探测法：冲突后依次找**下一个位置**(数组是**循环**的)，直到遇到**空闲**位置。查找时，如果映射到的位置不是想要的值，也会不断向后找，**如果遇到空闲位置，说明这个值不在哈希表中**(如果存在一定会向后移动到这个位置)。对于要删除的数不能**直接**把它从哈希表中删掉，这会**截断**其他值向后寻找的路径。因此将删除位置标记一个**特殊值**。
  + 二次探测法：冲突时按照$+1^2, -1^2, 2^2, -2^2, +3^2,+3^2，...$探测
  + 二度哈希：有多个哈希函数，使用第一个哈希函数冲突，则使用第二个哈希函数
+ 拉链法：将映射到同一个位置的值，用单链表连接起来









# 计算机网络





## 各层以及各层的协议

+ 应用层：应用程序之间提供数据传输服务，HTTP.,SMT,POP3,DNS
+ 传输层：为进程之间的提供服务，TCP UDP
+ 网络层：主机之间通信服务，ARP,ICMP,BGP
+ 链路层：相邻网络节点之间的数据传输，CSMA/CD
+ 物理层：在线路上传输bit



## 电路交换，报文交换和分组交换的区别

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/d7f8f5d748c8ca1274dac2c8333a8c32.jpeg#pic_center)

1. 电路交换——整个报文的比特流连续的从源点到达终点，类似于在一个管道中传输
2. 报文交换——整个报文先传送到相邻的节点，全部存储下来后，转发到下一个节点
3. 分组交换——单个分组先传送到相邻的节点，全部存储下来，转发到下一个节点



## 三次握手

防止已经失效的连接请求突然传送到了服务端，因而产生错误。这里已失效的连接请求指的是client发送的第一个连接请求并没有丢失，而是在延误了一段时间后才到达server，而服务器收到了这个报文后，如果不采用三次握手会认为连接请求建立了，然后一直等待client发送信息，导致资源浪费。

## 四次挥手

服务器接收客户端的中断请求时可能还有一些数据没有发送完毕，这时会先回复ACK表示收到了断开连接的请求，等到数据发送完之后再发Fin，断开服务器到客户端的数据传送。

## 流量控制

发送方发送速度过快，导致接收者来不及接收，那么就会发生分组丢失，流量控制的目的就是**防止分组丢失**。

接收方返回的 ACK 中会包含自己的接收窗口的大小，并且利用大小来控制发送方的数据发送。

假设在将**rwnd=0**发送给发送方后**接收方不会再返回任何数据**，这时因为**发送方无法知道接收方的缓存是否有新的空间**，发送方会被**阻塞**将不再发送数据。为此，**当接收方rwnd=0时**，发送方**会继续发送只有一个字节的报文段**，最终缓存开始清空，这些报文段会被**确认**，确认报文中将带有**非0的rwnd**

慢启动是TCP建立连接后的**第一个模式**，该模式下cwnd通常被**初始化为1MSS**，慢启动阶段cwnd**每经历一个RTT**(TCP一次性将窗口中所有的报文发出，所有报文确认的事件近似一个RTT)就会**翻倍**，慢启动的目的就是为了**快速找到上限**。

+ 出现**超时**，设置**阈值ssthresh为cwnd/2**，然后将**cwnd设为1**，这里试探到了上限，然后继续指数增长
+ **当cwnd到达阈值时**，会进入**拥塞避免**模式
+ 接收到**三次冗余确认**，进入**快速恢复**阶段，设置**阈值ssthresh为cwnd/2**，然后**cwnd = ssthresh + 3MSS**



**拥塞避免是一个速率缓慢且线性增长的过程**，这里每经历一个RTT，cwnd就增加**1**，假设`cwnd`包含`10`个报文的大小，则每接收到一个确认报文，`cwnd`增加1/10 MSS

+ 出现**超时**也就是出现拥塞，设置**阈值ssthresh为cwnd/2**，然后将**cwnd设为1**，进入**慢启动**，再次试探上限
+ 接收到**三次冗余确认**，进入**快速恢复**阶段，设置**阈值ssthresh为cwnd/2**，然后**cwnd = ssthresh + 3MSS**



收到三次冗余确认可能是出现了拥塞，但是直接进入到慢启动有点鲁莽，因为既然可以收到冗余的确认报文，表示拥塞不会太严重。

快速恢复阶段，每收到一个冗余确认报文(旧的)，cwnd就增加**1**

+ 接收到**新的确认报文**，**cwnd设置为ssthresh**，然后进入**拥塞避免**
+ 出现**超时**，设置**阈值ssthresh为cwnd/2**，然后将**cwnd设为1**，进入**慢启动**



简单总结，一旦超时就重置阈值和cwnd，重新开始慢启动；收到三次冗余确认，重置阈值和cwnd，进入快速恢复；慢启动达到阈值，进入拥塞避免；快速恢复收到新的确认报文进入拥塞避免；

## 拥塞控制

网络中很少有两台主机是直接相连的，发送到网络中的数据会通过**路由器转换**，但是路由器不是直接就能转发的，它首先要将收到的数据放入到内存中，再从中取出进行转发，而**路由器的内存是有限的**，同一时间到达某个路由器的数据太多，这个路由器将无法接收所有的数据，只能将一部分丢弃；或者同一台路由器数据太多，后面到达的数据将要等待较长的时间才会被转发。**网络中数据太多，导致某个路由器处理不过来或者处理地太慢，就是网络拥塞。**

拥塞控制就是在网络发送拥塞时，**减少向网络中发送数据的速度，防止恶性循环，在网络空闲时提高发送数据的速度，最大限度地利用网络资源。**

TCP拥塞控制算法包括三部分：**慢启动，拥塞避免，快速恢复**，其中前两个是**一定包括**的部分。





## 拥塞控制和流量控制的区别

拥塞控制：拥塞控制是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况	

流量控制：流量控制是作用于接收者的，它是控制发送者的发送速度从而使接收者来得及接收，防止分组丢失的



## 为什么有了MAC地址，还需要IP地址

需要IP地址进行路径选择



## DNS的工作原理

DNS解析有递归和迭代两种：

+ 递归：发送请求后等待返回结果
+ 迭代：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的IP地址，要么告诉本地服务器：“你下一步应当向哪一个域名服务器进行查询”。然后本地域名服务器再进行查询。

![img](./assets/v2-ea2fa0f3bcb5b6ebbad37e810ecf8280_1440w.jpg)



## ipv6和ipv4的区别

ipv6是128位地址，冒号十六进制，首部没有可选项，不允许中间路由器分片组装，只能由发送端处理

ipv4是32位地址，点分十进制















# 操作系统

## 线程的几种状态

阻塞，执行，就绪

## 线程共享和不共享的资源

不共享的有：栈，寄存器

共享的有：全局变量，堆，文件





## 计算机开机执行的第一条指令地址是什么

取决于处理器架构，对于x86来说是0xFFFFFFF0



## 解释一下join函数的意义，如何使用

用于等待子线程结束，它会阻塞父进程，等待子进程结束后，再唤醒父进程。

## 中断的分类有哪些？中断的实现过程？

硬中断：由外部硬件设备产生的中断信号，具有突发性。外部设备需要CPU处理时，会发送一个中断信号，CPU收到信号后先保存当前进程的状态，然后跳转到对应的中断处理程序，执行后恢复之前的状态，继续执行原来的任务。

软中断：由程序预先设定好的，执行中断指令产生的。软中断的执行过程和硬中断差不多



举个例子，你在家里打电话，若是这时候有人敲门，你中断了打电话的行为就叫作软中断，而若是是由于电话线出了问题致使你的电话中断了，这就叫作硬中断。

## 死锁以及产生死锁的原因

死锁是多个进程为了竞争资源而造成的相互等待的情况

产生死锁的四个条件

1. 资源同一时刻只能被一个进程访问
2. 持有资源的同时又能请求资源
3. 进程的资源不可被抢占
4. 存在循环等待





## 硬链接软链接

inode储存文件的相关信息：文件大小，所有者，权限，时间戳，数据块的位置等

- 硬链接：允许多个文件名指向同一个inode（索引节点），可以用不同的文件名访问相同的内容，并且删除一个文件名不会影响到其他文件名的访问。硬链接的创建不能跨文件系统
- 软链接：是一种特殊类型的文件，拥有独立的inode，文件内容是另一个文件的路径，相当于快捷方式，可以跨文件系统





# 编译原理

## 编译的过程

四个阶段预处理，编译，，汇编，链接

预处理：删除代码中的注释，替换掉宏



<img src="./assets/1059417-20220902232601285-1277551789.png" alt="image" style="zoom: 33%;" />

其中，词法分析，语法分析，语义分析，中间代码生成(三地址码，方便后续优化)只和**源语言**有关，因此被称为编译器的前端，在源代码的基础上生成中间表示；而后面的部分负责在中间表示的基础上生成目标代码(特定机器的汇编代码)，只与**目标语言有关**，称为后端或者叫综合部分。

然后执行汇编和链接，汇编将汇编代码变为机器代码，链接将多个目标文件和库文件链接为一个可执行文件。



## 静态链接和动态链接

| 概念         | 含义                                                         | 链接时间   |
| ------------ | ------------------------------------------------------------ | ---------- |
| **静态链接** | 在编译时就把用到的库代码“拷贝进”可执行文件中（一次打包到底） | 编译时完成 |
| **动态链接** | 在运行时才加载所需的库（就像临时借用外部资源）               | 运行时完成 |



更新库文件会影响到动态链接的程序，但是可执行程序的比较小，只包含引用信息。













## 图灵机是什么

图灵机是一种数学模型，它由三部分组成：

1. 无限长的纸带，纸带上被分为一个一个格子，每个格子可以储存一个符号
2. 读写头，可以去读取纸带上的符号，写入一个新符号，移动
3. 有限状态控制器，有若干个状态，其中一个是初始状态，根据当前状态和读到的符号决定下一步的操作

能够模拟任何算法。





# 数据库



## 三级模式两级印象

三级模式和两级映像

+ **模式(概念模式)：所有数据的逻辑结构和特征的描述，就是常用的基本表**
+ **外模式(用户模式)：用户用到的那部分数据的描述，对应视图**
+ **内模式(存储模式)：是对数据物理结构和存储方式的描述，是数据在数据库内部的组织方式**

视图是**虚表**，是对一个或多个表的查询结果的`逻辑表示`，是数据查询的`基本对象`，它**不储存数据**，而是储存一条查询语句的**结果**的定义，每次访问视图都会**执行这条查询**。



两级映像，用于保证物理独立性和逻辑独立性

- 外模式/模式映像：**定义外模式和模式之间的对应关系(表和视图之间的映像)，保证数据的逻辑独立性，若表中的数据改变，只需修改该映射，无需修改应用代码。**
- 模式/内模式映像：**表和物理存储之间的对应关系，保证数据的物理独立性，若改变了数据的存储方式，只需修改该映像，无需修改应用代码。**



## 数据库中的选择操作，什么时候应该用到索引？

索引是为表中一列或者多列建立的数据结构，用于快速定位满足条件的位置。

数据量特别大的时候，使用索引查找不必扫描整个表







# 机器学习

## 机器学习是什么，可以做什么

机器学习是使计算机从数据中自动学习经验，并在新的数据上进行预测或分类的的技术





# 政治

## 我国的反腐行动如何





## 对于社会核心价值观的了解





# 其他

## 论文级别

分为ABC类，A——国际顶级会议或期刊(CVPR)，B——国际权威会议或期刊(ECCV)，C——国际有影响会议或期刊(ICPR)





## 编译型语言和解释型语言

编译型语言：源代码通过编译器一次性转换为机器语言，然后再执行。效率更高，但是编译后的可执行文件无法跨平台，因为编译出的机器码与处理器和操作系统绑定

解释型语言：源代码通过解释器逐行读取并执行。调试更快，跨平台性好，只需安装解释器。



java是混合型语言，源代码现由编译器编译为平台无关的字节码，然后由跨平台的JVM解释执行，综合了两者的优点。

## 关键路径是什么

从起点到终点所经过的路径中，具有最长总耗时的一条路径，其上的任务称为关键任务









​	
